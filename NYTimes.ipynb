{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "import requests\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import ujson as json\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = config['API']['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json\" \n",
    "params = {'api-key':key\n",
    "          ,'q':'Underscore'\n",
    "          ,'begin_date':20160101\n",
    "          ,'end_date':20161221\n",
    "          ,'page':0}\n",
    "r = requests.get(url,params=params)\n",
    "results = r.json()\n",
    "# get the number of restuls\n",
    "total_results = results['response']['meta']['hits']\n",
    "# create integer for total pages\n",
    "total_pages = int(round(int(total_results),0))\n",
    "# prepare the documents\n",
    "docs = results['response']['docs']\n",
    "# create a list of lists of documents (page,doc)\n",
    "res_by_date = [(doc['pub_date'],doc) for doc in docs]\n",
    "# pack the results list with the page's documents\n",
    "results_by_date = []\n",
    "results_by_date.extend(res_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in range(1,total_pages):\n",
    "    # update to new page\n",
    "    params['page']=p\n",
    "    # get data\n",
    "    time.sleep(5.5)\n",
    "    r = requests.get(url,params=params)\n",
    "    results = r.json()\n",
    "    # grab the docs\n",
    "    docs = results['response']['docs']\n",
    "    # orgaize docs by (date,doc)\n",
    "    res_by_date = [(doc['pub_date'],doc) for doc in docs]\n",
    "    # append results\n",
    "    results_by_date.extend(res_by_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(results_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['response']['meta']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/2016-12-18_520recs_list_datetup_obj.pkl', 'wb') as fp:\n",
    "    pickle.dump(results_by_date, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = './data/2016-12-18_520recs_list_datetup.json'\n",
    "with open(filepath, 'w') as file_handler:\n",
    "    for item in results_by_date:\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['response']['docs'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources =[]\n",
    "for date,doc in results_by_date:\n",
    "    sources.append(doc['source'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(results_by_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the publication sources?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the date range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = set()\n",
    "for date,record in results_by_date:\n",
    "    dates.add(dateutil_parse(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (max(dates))\n",
    "print (min(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On what day are articles published?\n",
    "Build a heatmap similar to [D3 v4 Calendar View](https://bl.ocks.org/micahstubbs/89c6bd879d64aa511372064c6cf85711)\n",
    "<pre>\n",
    "Date,Open,High,Low,Close,Volume,Adj Close\n",
    "2010-10-01,10789.72,10907.41,10759.14,10829.68,4298910000,10829.68\n",
    "2010-09-30,10835.96,10960.99,10732.27,10788.05,4284160000,10788.05\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n1 data/2016-12-18_520recs_list_datetup.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_headline_tup = []\n",
    "for date, rec in results_by_date:\n",
    "    date_obj = dateutil_parse(date)\n",
    "    headline = rec['headline']['main']\n",
    "    date_headline_tup.append({'date':date_obj,'headline':headline})\n",
    "df=pd.DataFrame(date_headline_tup)\n",
    "df.index=df.date\n",
    "df['value'] = 1\n",
    "print(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekly_sum= df.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['weekday_name']=df.date.dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily = df.date.dt.weekday_name\n",
    "daily.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hourly = df.date.dt.hour\n",
    "hourly.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(results_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!jq data/2016-12-18_520recs_list_datetup.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize: Archived NYTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nyt_query(url= \"https://api.nytimes.com/svc/search/v2/articlesearch.json\" \n",
    "              , params =\n",
    "                  {'api-key':key\n",
    "                  ,'q':'Underscore'\n",
    "                  ,'begin_date':20160101\n",
    "                  ,'end_date':20161221\n",
    "                  ,'page':0}\n",
    "              , tup_date_doc = False\n",
    "              , fileName = 'data/{}_archive_results.json'.format(datetime.now().strftime('%Y-%m-%d'))\n",
    "         ):\n",
    "    \n",
    "    def eval():\n",
    "        if tup_date_doc:\n",
    "            res_by_date = [{\"pub_date\": doc['pub_date'],\"rec\":json.dumps(doc)} for doc in docs]\n",
    "        else:\n",
    "            res_by_date = docs\n",
    "            return res_by_date\n",
    "    # make initial request\n",
    "    r = requests.get(url,params=params)\n",
    "    results = r.json()\n",
    "    # get the number of restuls\n",
    "    total_results = results['response']['meta']['hits']\n",
    "    # create integer for total pages\n",
    "    results_per_page = 10\n",
    "    total_pages = int(round(int(total_results)/results_per_page,0))\n",
    "    # prepare the documents\n",
    "    docs = results['response']['docs']\n",
    "    # orgaize docs \n",
    "    res_by_date = eval()\n",
    "    # pack the results list with the page's documents\n",
    "    results_by_date = []\n",
    "    results_by_date.extend(res_by_date)\n",
    "    with open(fileName,'w') as f:\n",
    "        for res in res_by_date:\n",
    "            f.write(json.dumps(res)+'\\n')\n",
    "        print (total_pages)\n",
    "        for p in range(1,total_pages):\n",
    "            print(\"current page: {}\".format(10*p))\n",
    "            # update to new page\n",
    "            params['page']=p\n",
    "            # get data\n",
    "            time.sleep(1.5)\n",
    "            r = requests.get(url,params=params)\n",
    "            try: \n",
    "                results = r.json()\n",
    "            except ValueError as e:\n",
    "                print('ValueError: {}'.format(str(e)))\n",
    "                continue\n",
    "            # grab the docs\n",
    "            docs = results['response']['docs']\n",
    "            # orgaize docs \n",
    "            res_by_date = eval()\n",
    "            # append results\n",
    "            #results_by_date.extend(res_by_date)\n",
    "            # write results\n",
    "            for res in res_by_date:\n",
    "                f.write(json.dumps(res))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = str(2016)\n",
    "month = str(2) #(January ==1)\n",
    "url = \"https://api.nytimes.com/svc/archive/v1/YEAR/MONTH.json\".replace('YEAR',year).replace('MONTH',month)\n",
    "params = ({'api-key':key,'page':0})\n",
    "nyt_query(url=url,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(results_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wc -l data/2016-12-22_archive_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_by_date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wc -l data/2016-12-22_archive_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wc -l data/2016-12-22_headn7413_archive_results.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized counts\n",
    "This data come from all articles printed during the month of January in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_date_headline_tup = []\n",
    "with open('data/2016-12-22_headn7413_archive_results.json','r') as f:\n",
    "    for item in f:\n",
    "        rec = json.loads(item)\n",
    "        pub_date = dateutil_parse(rec['pub_date'])\n",
    "        headline = rec['headline']['main']\n",
    "        new_date_headline_tup.append({'date':date_obj,'headline':headline})\n",
    "df2=pd.DataFrame(new_date_headline_tup)\n",
    "df2.index=df2.date\n",
    "df2['value'] = 1\n",
    "df2['weekday_name']=df2.date.dt.weekday_name\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily = df2.date.dt.weekday_name\n",
    "#daily = df.date.dt.weekday_name\n",
    "daily.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wc -l data/2016-12-24_archive_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tup_lst = []\n",
    "with open('data/2016-12-22_headn7413_archive_results.json','r') as f:\n",
    "    for item in f:\n",
    "        rec = json.loads(item)\n",
    "        pub_date = dateutil_parse(rec['pub_date'])\n",
    "        headline = rec['headline']['main']\n",
    "        new_date_headline_tup.append({'date':date_obj,'headline':headline})\n",
    "df2=pd.DataFrame(new_date_headline_tup)\n",
    "df2.index=df2.date\n",
    "df2['value'] = 1\n",
    "df2['weekday_name']=df2.date.dt.weekday_name\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing XML from NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.nytimes.com/interactive/2016/01/28/upshot/donald-trump-twitter-insults.html'\n",
    "file_name = 'data/2017-01-26_test_page.html'\n",
    "page = requests.get(url)\n",
    "#print(page.text)\n",
    "#headers = {'Accept-Encoding': 'identity'}\n",
    "#r = requests.get(url, headers=headers)\n",
    "#print(r)\n",
    "#tree = html.fromstring(page.content)\n",
    "data = page.text\n",
    "\n",
    "with open(file_name,'w') as f:\n",
    "    f.write(data)\n",
    "    \n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "#for link in soup.find_all('a'):\n",
    "#    print(link.get('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PYTHONPATH='/Users/blehman/workspace/github/2016-12-16_NYTimesAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n",
    "html = browser.page_source\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(href)\n",
    "href.startswith('https://twitter.com/realDonaldTrump/status/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html)\n",
    "tweets = []\n",
    "for link in soup.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    if href==None:\n",
    "        continue\n",
    "    elif href.startswith('https://twitter.com/realDonaldTrump/status/'):\n",
    "        tweets.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src={} width=700 height=500></iframe>'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "tweets = []\n",
    "for div in soup.find_all(class_=\"g-insult-links-c\",limit=1):\n",
    "    print(div)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "tweets = []\n",
    "for a in soup.select('.g-insult-links-c a[href^=\"https://twitter.com/realDonaldTrump/status/\"]'):\n",
    "    name = a.parent.parent.parent.select('.g-entity-name')[0].string\n",
    "    title = a.parent.parent.parent.select('.g-entity-title')[0].string\n",
    "    link = a.attrs['href']\n",
    "    text = a.string[1:-2] #removing added quotes\n",
    "    date = a.next_sibling.string\n",
    "    tweets.append({\"name\":name\n",
    "                   ,\"title\":title\n",
    "                   ,\"link\":link\n",
    "                   ,\"body\":text\n",
    "                   ,\"date\":date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/2017-01-26_Trump_insults_NYT','w') as f:\n",
    "    f.write(json.dumps(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:2016-12-16_NYTimesAPI]",
   "language": "python",
   "name": "conda-env-2016-12-16_NYTimesAPI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
